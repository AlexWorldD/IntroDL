{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN-task.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "yUczRH-vgcu9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Generating names with recurrent neural networks\n",
        "\n",
        "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
        "\n",
        "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
        "\n",
        "It's dangerous to go alone, take these:"
      ]
    },
    {
      "metadata": {
        "id": "7McsHDrBg5IR",
        "colab_type": "code",
        "outputId": "0c355c5f-c7b0-43cf-9d1a-1605fa6984a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "! shred -u setup_google_colab.py\n",
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "setup_google_colab.setup_week5()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shred: setup_google_colab.py: failed to open for writing: No such file or directory\n",
            "--2019-02-05 14:02:09--  https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3792 (3.7K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "setup_google_colab. 100%[===================>]   3.70K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-02-05 14:02:10 (77.3 MB/s) - ‘setup_google_colab.py’ saved [3792/3792]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.696201Z",
          "start_time": "2018-08-13T20:26:38.104103Z"
        },
        "id": "9NsY-xAegcu_",
        "colab_type": "code",
        "outputId": "7d680edf-af90-4777-da3d-8cea340608f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import keras_utils\n",
        "import tqdm_utils"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.0-rc0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "XtfjHpiFhKCx",
        "colab_type": "code",
        "outputId": "752bd845-e4c5-4464-b2d0-a9b4d2df0f4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "fWnwwNwigcvC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load data\n",
        "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
        "\n",
        "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.701832Z",
          "start_time": "2018-08-13T20:26:42.697766Z"
        },
        "id": "Khhenn9GgcvD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "start_token = \" \"  # so that the network knows that we're generating a first token\n",
        "\n",
        "# this is the token for padding,\n",
        "# we will add fake pad token at the end of names \n",
        "# to make them of equal size for further batching\n",
        "pad_token = \"#\"\n",
        "\n",
        "with open(\"names\") as f:\n",
        "    names = f.read()[:-1].split('\\n')\n",
        "    names = [start_token + name for name in names]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.707885Z",
          "start_time": "2018-08-13T20:26:42.703302Z"
        },
        "id": "SlrhbH7VgcvG",
        "colab_type": "code",
        "outputId": "bc3371cd-4001-49ea-89ee-d7b0eec1fef1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "print('number of samples:', len(names))\n",
        "for x in names[::1000]:\n",
        "    print(x)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of samples: 7944\n",
            " Abagael\n",
            " Claresta\n",
            " Glory\n",
            " Liliane\n",
            " Prissie\n",
            " Geeta\n",
            " Giovanne\n",
            " Piggy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.857411Z",
          "start_time": "2018-08-13T20:26:42.709371Z"
        },
        "id": "-z0I2rj-gcvH",
        "colab_type": "code",
        "outputId": "d0e1fe48-fa87-4e1f-debd-4974db0da38c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = max(map(len, names))\n",
        "print(\"max length:\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len, names)), bins=25);"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max length: 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEHCAYAAACgHI2PAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ljTgaN_CgcvK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Text processing\n",
        "\n",
        "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.864592Z",
          "start_time": "2018-08-13T20:26:42.858725Z"
        },
        "id": "0JxuGxFlgcvL",
        "colab_type": "code",
        "outputId": "f385180c-8ec7-4bff-9e36-0ef98c9e8156",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "tokens = set(''.join(names)+pad_token)\n",
        "\n",
        "tokens = list(tokens)\n",
        "n_tokens = len(tokens)\n",
        "print ('n_tokens:', n_tokens)\n",
        "\n",
        "assert 50 < n_tokens < 60"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n_tokens: 56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o6W6169ggcvN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Cast everything from symbols into identifiers\n",
        "\n",
        "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
        "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
        "\n",
        "To create such dictionary, let's assign `token_to_id`"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.870330Z",
          "start_time": "2018-08-13T20:26:42.866135Z"
        },
        "id": "cVawOlB7gcvO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "token_to_id = dict(zip(tokens, range(len(tokens)))) # {symbol -> its  index in tokens}\n",
        "\n",
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.875943Z",
          "start_time": "2018-08-13T20:26:42.871834Z"
        },
        "id": "KTNVAeNDgcvU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def to_matrix(names, max_len=None, pad=token_to_id[pad_token], dtype=np.int32):\n",
        "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len, names))\n",
        "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
        "\n",
        "    for i in range(len(names)):\n",
        "        name_ix = list(map(token_to_id.get, names[i]))\n",
        "        names_ix[i, :len(name_ix)] = name_ix\n",
        "\n",
        "    return names_ix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.883107Z",
          "start_time": "2018-08-13T20:26:42.877186Z"
        },
        "id": "JucfbMZXgcvX",
        "colab_type": "code",
        "outputId": "d861c153-8bff-4765-932d-3c2c0596ad3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
        "print('\\n'.join(names[::2000]))\n",
        "print(to_matrix(names[::2000]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Abagael\n",
            " Glory\n",
            " Prissie\n",
            " Giovanne\n",
            "[[46 16 41 19 38 19 53 54 12]\n",
            " [46 21 54 29 45 18 12 12 12]\n",
            " [46  8 45 15 51 51 15 53 12]\n",
            " [46 21 15 29 10 19 42 42 53]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "edVFK2C-gcvb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Defining a recurrent neural network\n",
        "\n",
        "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
        "<img src=\"./rnn.png\" width=600>\n",
        "\n",
        "Since we're training a language model, there should also be:\n",
        "* An embedding layer that converts character id x_t to a vector.\n",
        "* An output layer that predicts probabilities of next phoneme based on h_t+1"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.039419Z",
          "start_time": "2018-08-13T20:26:42.884581Z"
        },
        "id": "jh8Y3poFgcvc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# remember to reset your session if you change your graph!\n",
        "s = keras_utils.reset_tf_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.044903Z",
          "start_time": "2018-08-13T20:26:44.041084Z"
        },
        "id": "I1NPfw74gcve",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.layers import concatenate, Dense, Embedding\n",
        "\n",
        "rnn_num_units = 64  # size of hidden state\n",
        "embedding_size = 16  # for characters\n",
        "\n",
        "# Let's create layers for our recurrent network\n",
        "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
        "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
        "\n",
        "# an embedding layer that converts character ids into embeddings\n",
        "embed_x = Embedding(n_tokens, embedding_size)\n",
        "\n",
        "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
        "get_h_next = Dense(rnn_num_units, activation='tanh')\n",
        "\n",
        "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
        "get_probas = Dense(n_tokens, activation=\"softmax\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7RY-n-rGgcvg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will generate names character by character starting with `start_token`:\n",
        "\n",
        "<img src=\"./char-nn.png\" width=600>"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.053212Z",
          "start_time": "2018-08-13T20:26:44.048389Z"
        },
        "id": "Z_i4Jsd-gcvh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def rnn_one_step(x_t, h_t):\n",
        "    \"\"\"\n",
        "    Recurrent neural network step that produces \n",
        "    probabilities for next token x_t+1 and next state h_t+1\n",
        "    given current input x_t and previous state h_t.\n",
        "    We'll call this method repeatedly to produce the whole sequence.\n",
        "    \n",
        "    You're supposed to \"apply\" above layers to produce new tensors.\n",
        "    Follow inline instructions to complete the function.\n",
        "    \"\"\"\n",
        "    # convert character id into embedding\n",
        "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
        "    \n",
        "    # concatenate x_t embedding and previous h_t state\n",
        "    x_and_h = tf.concat([x_t_emb, h_t], 1)\n",
        "    \n",
        "    # compute next state given x_and_h\n",
        "    h_next = get_h_next(x_and_h)\n",
        "    \n",
        "    # get probabilities for language model P(x_next|h_next)\n",
        "    output_probas = get_probas(h_next)\n",
        "    \n",
        "    return output_probas, h_next"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6hYMngqMgcvj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: loop\n",
        "\n",
        "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
        "\n",
        "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.342948Z",
          "start_time": "2018-08-13T20:26:44.056136Z"
        },
        "id": "ANpfd5OEgcvk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
        "batch_size = tf.shape(input_sequence)[0]\n",
        "\n",
        "predicted_probas = []\n",
        "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
        "\n",
        "for t in range(MAX_LENGTH):\n",
        "    x_t = input_sequence[:, t]  # column t\n",
        "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
        "    \n",
        "    h_prev = h_next\n",
        "    predicted_probas.append(probas_next)\n",
        "    \n",
        "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
        "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
        "\n",
        "# next to last token prediction is not needed\n",
        "predicted_probas = predicted_probas[:, :-1, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ohn-UD7Wgcvn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: loss and gradients\n",
        "\n",
        "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
        "\n",
        "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
        "\n",
        "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.354310Z",
          "start_time": "2018-08-13T20:26:44.344648Z"
        },
        "id": "daEPIVZAgcvn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# flatten predictions to [batch*time, n_tokens]\n",
        "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
        "\n",
        "# flatten answers (next tokens) and one-hot encode them\n",
        "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GHVqj0QJgcvp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
        "\n",
        "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
        "\n",
        "For simplicity you can ignore this comment, it's up to you."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:45.076642Z",
          "start_time": "2018-08-13T20:26:44.355594Z"
        },
        "id": "vFwBKVsOgcvq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
        "# Mind that predictions are probabilities and NOT logits!\n",
        "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
        "loss = tf.reduce_mean(keras.losses.categorical_crossentropy(answers_matrix, predictions_matrix))\n",
        "\n",
        "optimize = tf.train.AdamOptimizer().minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uSvb1lJNgcvs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: training"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.322187Z",
          "start_time": "2018-08-13T20:26:45.078296Z"
        },
        "id": "kmPm9dqXgcvt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "37bb2ffb-d179-49cd-cfb4-f5708e1a2454"
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "batch_size = 32\n",
        "history = []\n",
        "\n",
        "for i in range(1000):\n",
        "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
        "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
        "    \n",
        "    history.append(loss_i)\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history, label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "PGNzgWrGgcvx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: sampling\n",
        "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.341196Z",
          "start_time": "2018-08-13T20:26:55.323787Z"
        },
        "id": "Xe2iTUU6gcvy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_t = tf.placeholder(tf.int32, (1,))\n",
        "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
        "\n",
        "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
        "# We reuse all parameters thanks to functional API usage.\n",
        "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
        "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
        "next_probs, next_h = rnn_one_step(x_t, h_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.346422Z",
          "start_time": "2018-08-13T20:26:55.342659Z"
        },
        "id": "vRCKPmozgcv0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
        "    '''\n",
        "    This function generates text given a `seed_phrase` as a seed.\n",
        "    Remember to include start_token in seed phrase!\n",
        "    Parameter `max_length` is used to set the number of characters in prediction.\n",
        "    '''\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    s.run(tf.assign(h_t, h_t.initial_value))\n",
        "    \n",
        "    # feed the seed phrase, if any\n",
        "    for ix in x_sequence[:-1]:\n",
        "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
        "    \n",
        "    # start generating\n",
        "    for _ in range(max_length-len(seed_phrase)):\n",
        "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
        "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:58.458115Z",
          "start_time": "2018-08-13T20:26:55.347900Z"
        },
        "id": "z85YxeDJgcv1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "ad3eb107-c9f6-4c1d-a6bb-c8ec2657b2e1"
      },
      "cell_type": "code",
      "source": [
        "# without prefix\n",
        "for _ in range(10):\n",
        "    print(generate_sample())"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Lorredn\n",
            " Erra\n",
            " Jelolina\n",
            " Merriy\n",
            " Balfy\n",
            " Lesfien\n",
            " Agcipty\n",
            " Marl\n",
            " Nawainon\n",
            " Certs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:01.986726Z",
          "start_time": "2018-08-13T20:26:58.459810Z"
        },
        "id": "5Vtkx5Zegcv3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "1295b0c1-d52c-4df0-d627-04ff97239bc3"
      },
      "cell_type": "code",
      "source": [
        "# with prefix conditioning\n",
        "for _ in range(10):\n",
        "    print(generate_sample(' Trump'))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Trumprie\n",
            " Trumpord\n",
            " Trumpyra\n",
            " Trumphan\n",
            " Trumpe\n",
            " Trumpy\n",
            " Trumpe\n",
            " Trumpe\n",
            " Trumpia\n",
            " Trumpy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ap017mF8gcv6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Submit to Coursera"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:02.004926Z",
          "start_time": "2018-08-13T20:40:02.000821Z"
        },
        "id": "oOZs1zYvgcv6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# token expires every 30 min\n",
        "COURSERA_TOKEN = \"\"\n",
        "COURSERA_EMAIL = \"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:18.923357Z",
          "start_time": "2018-08-13T20:40:03.549343Z"
        },
        "id": "dgNbzTongcv-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "5628b5e0-3be4-476a-c890-37f0d789465b"
      },
      "cell_type": "code",
      "source": [
        "from submit import submit_char_rnn\n",
        "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
        "submission = (history, samples)\n",
        "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************\n",
            "\n",
            "Submitted to Coursera platform. See results on assignment page!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "558zBJaDgcv_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Try it out!\n",
        "\n",
        "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
        "\n",
        "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
        "\n",
        "* Novels/poems/songs of your favorite author\n",
        "* News titles/clickbait titles\n",
        "* Source code of Linux or Tensorflow\n",
        "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
        "* Melody in notes/chords format\n",
        "* IKEA catalog titles\n",
        "* Pokemon names\n",
        "* Cards from Magic, the Gathering / Hearthstone\n",
        "\n",
        "If you're willing to give it a try, here's what you wanna look at:\n",
        "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
        "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
        "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
        "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
        "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
        "\n",
        "__Good hunting!__"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "00LMbuxigcwB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Bonus level: dynamic RNNs\n",
        "\n",
        "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
        "\n",
        "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
        "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
        "\n",
        "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.975354Z",
          "start_time": "2018-08-13T20:27:12.737529Z"
        },
        "id": "a2643OqEgcwB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "e3df9eec-add6-4f15-aab5-85cd708998a4"
      },
      "cell_type": "code",
      "source": [
        "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
        "    def call(self, input, state):\n",
        "        # from docs:\n",
        "        # Returns:\n",
        "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
        "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
        "        return rnn_one_step(input[:, 0], state)\n",
        "    \n",
        "    @property\n",
        "    def output_size(self):\n",
        "        return n_tokens\n",
        "    \n",
        "cell = CustomRNN(rnn_num_units)\n",
        "\n",
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "    \n",
        "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
        "\n",
        "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
        "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-31-5f3812e903bf>:13: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-31-5f3812e903bf>:17: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "LSTM outputs for each step [batch,time,n_tokens]:\n",
            "(10, 50, 56)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XMEBTWBrgcwD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
        "\n",
        "You can also use any pre-implemented RNN cell:"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.981697Z",
          "start_time": "2018-08-13T20:27:12.977590Z"
        },
        "id": "eH1eNEEMgcwD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "32577f4a-8861-4fbe-e0a6-eca25d5f40ef"
      },
      "cell_type": "code",
      "source": [
        "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
        "    if obj.endswith('Cell'):\n",
        "        print(obj, end=\"\\t\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BasicLSTMCell\tBasicRNNCell\tGRUCell\tLSTMCell\tMultiRNNCell\tRNNCell\tBasicLSTMCell\tBasicRNNCell\tBidirectionalGridLSTMCell\tConv1DLSTMCell\tConv2DLSTMCell\tConv3DLSTMCell\tConvLSTMCell\tCoupledInputForgetGateLSTMCell\tFusedRNNCell\tGLSTMCell\tGRUBlockCell\tGRUCell\tGridLSTMCell\tIndRNNCell\tIndyGRUCell\tIndyLSTMCell\tIntersectionRNNCell\tLSTMBlockCell\tLSTMBlockFusedCell\tLSTMCell\tLayerNormBasicLSTMCell\tLayerRNNCell\tMultiRNNCell\tNASCell\tPhasedLSTMCell\tRNNCell\tSRUCell\tTimeFreqLSTMCell\tUGRNNCell\t"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:13.168207Z",
          "start_time": "2018-08-13T20:27:12.986884Z"
        },
        "id": "qVR7BpBOgcwG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "7a7915be-281b-47cb-8e4d-2ffc2f6fb8b0"
      },
      "cell_type": "code",
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "\n",
        "inputs_embedded = embed_x(input_sequence)\n",
        "\n",
        "# standard cell returns hidden state as output!\n",
        "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
        "\n",
        "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
        "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-33-62766a2145fb>:6: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "LSTM hidden state for each step [batch,time,rnn_num_units]:\n",
            "(10, 50, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}