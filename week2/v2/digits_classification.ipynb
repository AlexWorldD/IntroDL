{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "digits_classification.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "fZhifit-cfxB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Initialisation for TensorFlow as well as grading system:\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "xFj8f-zBcaET",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "8453d15d-a1dc-4558-e3f5-71e7fbf583fc"
      },
      "cell_type": "code",
      "source": [
        "! shred -u setup_google_colab.py\n",
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "setup_google_colab.setup_week2()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shred: setup_google_colab.py: failed to open for writing: No such file or directory\n",
            "--2018-12-11 13:26:56--  https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3595 (3.5K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "setup_google_colab. 100%[===================>]   3.51K  --.-KB/s    in 0s      \n",
            "\n",
            "2018-12-11 13:26:57 (62.1 MB/s) - ‘setup_google_colab.py’ saved [3595/3595]\n",
            "\n",
            "**************************************************\n",
            "inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "**************************************************\n",
            "cifar-10-batches-py.tar.gz\n",
            "**************************************************\n",
            "mnist.npz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KiWubX1VboLf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# MNIST digits classification with TensorFlow"
      ]
    },
    {
      "metadata": {
        "id": "wqAkH9x4boLg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/AlexWorldD/IntroDL/blob/master/week2/v2/images/mnist_sample.png?raw=1\" style=\"width:30%\">"
      ]
    },
    {
      "metadata": {
        "id": "NC-lzXa8boLh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "34da5fe5-2efb-4645-b1b6-040143f5371d"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "print(\"We're using TF\", tf.__version__)\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"../..\")\n",
        "import grading\n",
        "\n",
        "import matplotlib_utils\n",
        "from importlib import reload\n",
        "reload(matplotlib_utils)\n",
        "\n",
        "import grading_utils\n",
        "reload(grading_utils)\n",
        "\n",
        "import keras_utils\n",
        "from keras_utils import reset_tf_session"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We're using TF 1.12.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "AwAiQA9Ic5M9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Check that our GPU is working"
      ]
    },
    {
      "metadata": {
        "id": "qyatO_Rcc-x5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "15ceb5a7-409d-4569-ddd6-4a067c0b5843"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "YPH99xbNboLj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Fill in your Coursera token and email\n",
        "To successfully submit your answers to our grader, please fill in your Coursera submission token and email"
      ]
    },
    {
      "metadata": {
        "id": "FJY8lg0sboLk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "grader = grading.Grader(assignment_key=\"XtD7ho3TEeiHQBLWejjYAA\", \n",
        "                        all_parts=[\"9XaAS\", \"vmogZ\", \"RMv95\", \"i8bgs\", \"rE763\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5GuGkzP5boLn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# token expires every 30 min\n",
        "COURSERA_TOKEN = \"### YOUR TOKEN HERE ###\"\n",
        "COURSERA_EMAIL = \"### YOUR EMAIL HERE ###\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LArbJxxdboLp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Look at the data\n",
        "\n",
        "In this task we have 50000 28x28 images of digits from 0 to 9.\n",
        "We will train a classifier on this data."
      ]
    },
    {
      "metadata": {
        "id": "yJHklnQcboLp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import preprocessed_mnist\n",
        "X_train, y_train, X_val, y_val, X_test, y_test = preprocessed_mnist.load_dataset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0zqc3VojboLs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# X contains rgb values divided by 255\n",
        "print(\"X_train [shape %s] sample patch:\\n\" % (str(X_train.shape)), X_train[1, 15:20, 5:10])\n",
        "print(\"A closeup of a sample patch:\")\n",
        "plt.imshow(X_train[1, 15:20, 5:10], cmap=\"Greys\")\n",
        "plt.show()\n",
        "print(\"And the whole sample:\")\n",
        "plt.imshow(X_train[1], cmap=\"Greys\")\n",
        "plt.show()\n",
        "print(\"y_train [shape %s] 10 samples:\\n\" % (str(y_train.shape)), y_train[:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1kHmRO7YboLu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Linear model\n",
        "\n",
        "Your task is to train a linear classifier $\\vec{x} \\rightarrow y$ with SGD using TensorFlow.\n",
        "\n",
        "You will need to calculate a logit (a linear transformation) $z_k$ for each class: \n",
        "$$z_k = \\vec{x} \\cdot \\vec{w_k} + b_k \\quad k = 0..9$$\n",
        "\n",
        "And transform logits $z_k$ to valid probabilities $p_k$ with softmax: \n",
        "$$p_k = \\frac{e^{z_k}}{\\sum_{i=0}^{9}{e^{z_i}}} \\quad k = 0..9$$\n",
        "\n",
        "We will use a cross-entropy loss to train our multi-class classifier:\n",
        "$$\\text{cross-entropy}(y, p) = -\\sum_{k=0}^{9}{\\log(p_k)[y = k]}$$ \n",
        "\n",
        "where \n",
        "$$\n",
        "[x]=\\begin{cases}\n",
        "       1, \\quad \\text{if $x$ is true} \\\\\n",
        "       0, \\quad \\text{otherwise}\n",
        "    \\end{cases}\n",
        "$$\n",
        "\n",
        "Cross-entropy minimization pushes $p_k$ close to 1 when $y = k$, which is what we want.\n",
        "\n",
        "Here's the plan:\n",
        "* Flatten the images (28x28 -> 784) with `X_train.reshape((X_train.shape[0], -1))` to simplify our linear model implementation\n",
        "* Use a matrix placeholder for flattened `X_train`\n",
        "* Convert `y_train` to one-hot encoded vectors that are needed for cross-entropy\n",
        "* Use a shared variable `W` for all weights (a column $\\vec{w_k}$ per class) and `b` for all biases.\n",
        "* Aim for ~0.93 validation accuracy"
      ]
    },
    {
      "metadata": {
        "id": "4NACB13eboLv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train_flat = X_train.reshape((X_train.shape[0], -1))\n",
        "print(X_train_flat.shape)\n",
        "\n",
        "X_val_flat = X_val.reshape((X_val.shape[0], -1))\n",
        "print(X_val_flat.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XMRlGoezboLx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "\n",
        "y_train_oh = keras.utils.to_categorical(y_train, 10)\n",
        "y_val_oh = keras.utils.to_categorical(y_val, 10)\n",
        "\n",
        "print(y_train_oh.shape)\n",
        "print(y_train_oh[:3], y_train[:3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KLYxsg3KboL0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# run this again if you remake your graph\n",
        "s = reset_tf_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bOWH6BoWboL3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Model parameters: W and b\n",
        "W = ### YOUR CODE HERE ### tf.get_variable(...) with shape[0] = 784\n",
        "b = ### YOUR CODE HERE ### tf.get_variable(...)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UKDXxHh3boL5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Placeholders for the input data\n",
        "input_X = ### YOUR CODE HERE ### tf.placeholder(...) for flat X with shape[0] = None for any batch size\n",
        "input_y = ### YOUR CODE HERE ### tf.placeholder(...) for one-hot encoded true labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gTeWJ8suboL6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Compute predictions\n",
        "logits = ### YOUR CODE HERE ### logits for input_X, resulting shape should be [input_X.shape[0], 10]\n",
        "probas = ### YOUR CODE HERE ### apply tf.nn.softmax to logits\n",
        "classes = ### YOUR CODE HERE ### apply tf.argmax to find a class index with highest probability\n",
        "\n",
        "# Loss should be a scalar number: average loss over all the objects with tf.reduce_mean().\n",
        "# Use tf.nn.softmax_cross_entropy_with_logits on top of one-hot encoded input_y and logits.\n",
        "# It is identical to calculating cross-entropy on top of probas, but is more numerically friendly (read the docs).\n",
        "loss = ### YOUR CODE HERE ### cross-entropy loss\n",
        "\n",
        "# Use a default tf.train.AdamOptimizer to get an SGD step\n",
        "step = ### YOUR CODE HERE ### optimizer step that minimizes the loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "96xyfmpZboL8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "BATCH_SIZE = 512\n",
        "EPOCHS = 40\n",
        "\n",
        "# for logging the progress right here in Jupyter (for those who don't have TensorBoard)\n",
        "simpleTrainingCurves = matplotlib_utils.SimpleTrainingCurves(\"cross-entropy\", \"accuracy\")\n",
        "\n",
        "for epoch in range(EPOCHS):  # we finish an epoch when we've looked at all training samples\n",
        "    \n",
        "    batch_losses = []\n",
        "    for batch_start in range(0, X_train_flat.shape[0], BATCH_SIZE):  # data is already shuffled\n",
        "        _, batch_loss = s.run([step, loss], {input_X: X_train_flat[batch_start:batch_start+BATCH_SIZE], \n",
        "                                             input_y: y_train_oh[batch_start:batch_start+BATCH_SIZE]})\n",
        "        # collect batch losses, this is almost free as we need a forward pass for backprop anyway\n",
        "        batch_losses.append(batch_loss)\n",
        "\n",
        "    train_loss = np.mean(batch_losses)\n",
        "    val_loss = s.run(loss, {input_X: X_val_flat, input_y: y_val_oh})  # this part is usually small\n",
        "    train_accuracy = accuracy_score(y_train, s.run(classes, {input_X: X_train_flat}))  # this is slow and usually skipped\n",
        "    valid_accuracy = accuracy_score(y_val, s.run(classes, {input_X: X_val_flat}))  \n",
        "    simpleTrainingCurves.add(train_loss, val_loss, train_accuracy, valid_accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JijpeRR5boL-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Submit a linear model"
      ]
    },
    {
      "metadata": {
        "id": "_eFDILIbboMA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## GRADED PART, DO NOT CHANGE!\n",
        "# Testing shapes \n",
        "grader.set_answer(\"9XaAS\", grading_utils.get_tensors_shapes_string([W, b, input_X, input_y, logits, probas, classes]))\n",
        "# Validation loss\n",
        "grader.set_answer(\"vmogZ\", s.run(loss, {input_X: X_val_flat, input_y: y_val_oh}))\n",
        "# Validation accuracy\n",
        "grader.set_answer(\"RMv95\", accuracy_score(y_val, s.run(classes, {input_X: X_val_flat})))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "owiIRKHqboMD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# you can make submission with answers so far to check yourself at this stage\n",
        "grader.submit(COURSERA_EMAIL, COURSERA_TOKEN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HfJ9dyIQboMF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# MLP with hidden layers"
      ]
    },
    {
      "metadata": {
        "id": "JoUWt7XxboMH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Previously we've coded a dense layer with matrix multiplication by hand. \n",
        "But this is not convenient, you have to create a lot of variables and your code becomes a mess. \n",
        "In TensorFlow there's an easier way to make a dense layer:\n",
        "```python\n",
        "hidden1 = tf.layers.dense(inputs, 256, activation=tf.nn.sigmoid)\n",
        "```\n",
        "\n",
        "That will create all the necessary variables automatically.\n",
        "Here you can also choose an activation function (remember that we need it for a hidden layer!).\n",
        "\n",
        "Now define the MLP with 2 hidden layers and restart training with the cell above.\n",
        "\n",
        "You're aiming for ~0.97 validation accuracy here."
      ]
    },
    {
      "metadata": {
        "id": "PisIRDDgboMH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# write the code here to get a new `step` operation and then run the cell with training loop above.\n",
        "# name your variables in the same way (e.g. logits, probas, classes, etc) for safety.\n",
        "### YOUR CODE HERE ###"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1Hw0YvWCboMK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Submit the MLP with 2 hidden layers\n",
        "Run these cells after training the MLP with 2 hidden layers"
      ]
    },
    {
      "metadata": {
        "id": "mxz5hdBPboMM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## GRADED PART, DO NOT CHANGE!\n",
        "# Validation loss for MLP\n",
        "grader.set_answer(\"i8bgs\", s.run(loss, {input_X: X_val_flat, input_y: y_val_oh}))\n",
        "# Validation accuracy for MLP\n",
        "grader.set_answer(\"rE763\", accuracy_score(y_val, s.run(classes, {input_X: X_val_flat})))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "61a905xdboMO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# you can make submission with answers so far to check yourself at this stage\n",
        "grader.submit(COURSERA_EMAIL, COURSERA_TOKEN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Px-khp79boMQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}